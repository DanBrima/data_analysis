{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Assignment 1 — Fish Dataset (KaggleHub) — EDA + KFold CNN Baseline\n",
        "\n",
        "This notebook keeps the same workflow as before (EDA → model → KFold evaluation),\n",
        "with the **minimal changes needed** to use the Kaggle dataset `crowww/a-large-scale-fish-dataset` via `kagglehub`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# If you get ModuleNotFoundError, run this cell once\n",
        "%pip -q install kagglehub torch torchvision scikit-learn matplotlib pillow numpy tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import random\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Download dataset with KaggleHub\n",
        "KaggleHub downloads the dataset to a local cache and returns the path.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /Users/danbrima/.cache/kagglehub/datasets/crowww/a-large-scale-fish-dataset/versions/2\n",
            "DATA_DIR: /Users/danbrima/.cache/kagglehub/datasets/crowww/a-large-scale-fish-dataset/versions/2/Fish_Dataset/Fish_Dataset\n",
            "DATA_DIR exists: True\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"crowww/a-large-scale-fish-dataset\")\n",
        "dataset_root = Path(path)\n",
        "print(\"Path to dataset files:\", dataset_root)\n",
        "\n",
        "# The images are typically under Fish_Dataset/\n",
        "DATA_DIR = dataset_root / \"Fish_Dataset\" / \"Fish_Dataset\"\n",
        "print(\"DATA_DIR:\", DATA_DIR)\n",
        "print(\"DATA_DIR exists:\", DATA_DIR.exists())\n",
        "\n",
        "# If this is False (dataset structure changed), inspect subfolders and set DATA_DIR accordingly.\n",
        "if not DATA_DIR.exists():\n",
        "    print(\"Subfolders under dataset_root:\")\n",
        "    for p in dataset_root.iterdir():\n",
        "        if p.is_dir():\n",
        "            print(\" -\", p.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) EDA\n",
        "We compute:\n",
        "- number of classes\n",
        "- total images\n",
        "- class distribution\n",
        "- sample image size/mode\n",
        "- show example images per class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_class_names(root_dir: Path):\n",
        "    return sorted([d.name for d in root_dir.iterdir() if d.is_dir()])\n",
        "\n",
        "\n",
        "def get_image_paths(root_dir: Path):\n",
        "    exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "    return [p for p in root_dir.glob(\"*/*\") if p.is_file() and p.suffix.lower() in exts]\n",
        "\n",
        "\n",
        "def inspect_image(image_path: Path):\n",
        "    with Image.open(image_path) as img:\n",
        "        return img.size, img.mode\n",
        "\n",
        "\n",
        "def plot_class_distribution(counter: Counter, title: str):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.bar(counter.keys(), counter.values())\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.title(title)\n",
        "    plt.ylabel(\"Number of images\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def show_samples_per_class(root_dir: Path, samples_per_class=2):\n",
        "    class_dirs = get_class_names(root_dir)\n",
        "    plt.figure(figsize=(samples_per_class * 3, len(class_dirs) * 3))\n",
        "    plot_idx = 1\n",
        "\n",
        "    for cls in class_dirs:\n",
        "        images = [p for p in (root_dir / cls).iterdir() if p.is_file()\n",
        "                  and p.suffix.lower() in (\".jpg\", \".jpeg\", \".png\")]\n",
        "        if not images:\n",
        "            continue\n",
        "        samples = random.sample(images, min(samples_per_class, len(images)))\n",
        "\n",
        "        for img_path in samples:\n",
        "            with Image.open(img_path) as img:\n",
        "                plt.subplot(len(class_dirs), samples_per_class, plot_idx)\n",
        "                plt.imshow(img)\n",
        "                plt.axis(\"off\")\n",
        "                plt.title(cls)\n",
        "                plot_idx += 1\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DATASET SIZE]\n",
            "Total images: 0\n",
            "\n",
            "[CLASSES]\n",
            "Number of classes: 9\n",
            "['Black Sea Sprat', 'Gilt-Head Bream', 'Hourse Mackerel', 'Red Mullet', 'Red Sea Bream', 'Sea Bass', 'Shrimp', 'Striped Red Mullet', 'Trout']\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(classes))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(classes)\n\u001b[0;32m---> 11\u001b[0m sample_size, sample_mode \u001b[38;5;241m=\u001b[39m inspect_image(\u001b[43mall_images\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[SAMPLE IMAGE INFO]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResolution (W x H):\u001b[39m\u001b[38;5;124m\"\u001b[39m, sample_size)\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "all_images = get_image_paths(DATA_DIR)\n",
        "classes = get_class_names(DATA_DIR)\n",
        "\n",
        "print(\"[DATASET SIZE]\")\n",
        "print(\"Total images:\", len(all_images))\n",
        "\n",
        "print(\"\\n[CLASSES]\")\n",
        "print(\"Number of classes:\", len(classes))\n",
        "print(classes)\n",
        "\n",
        "sample_size, sample_mode = inspect_image(all_images[0])\n",
        "print(\"\\n[SAMPLE IMAGE INFO]\")\n",
        "print(\"Resolution (W x H):\", sample_size)\n",
        "print(\"Color mode:\", sample_mode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = [p.parent.name for p in all_images]\n",
        "class_counts = Counter(labels)\n",
        "\n",
        "print(\"[CLASS DISTRIBUTION]\")\n",
        "print(\"Min class size:\", min(class_counts.values()))\n",
        "print(\"Max class size:\", max(class_counts.values()))\n",
        "\n",
        "plot_class_distribution(class_counts, \"Class distribution (Fish dataset)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "show_samples_per_class(DATA_DIR, samples_per_class=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Model + KFold Cross Validation (K ≥ 5)\n",
        "\n",
        "We keep the same simple CNN baseline. Main changes vs the zip-based dataset:\n",
        "- use `ImageFolder(DATA_DIR, ...)`\n",
        "- build train/val subsets using `StratifiedKFold` over `dataset.samples`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "IMG_SIZE = 224\n",
        "\n",
        "train_tf = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    # Random horizontal flipping is used as a data augmentation technique.\n",
        "    # For fish species classification, left/right orientation does not change the label,\n",
        "    # so flipping helps the model learn orientation-invariant features.\n",
        "    # This increases data diversity, reduces overfitting, and improves generalization.\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "eval_tf = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "base_ds_for_targets = ImageFolder(DATA_DIR, transform=eval_tf)\n",
        "num_classes = len(base_ds_for_targets.classes)\n",
        "print(\"num_classes:\", num_classes)\n",
        "print(\"classes:\", base_ds_for_targets.classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SmallCNN(nn.Module):\n",
        "    def __init__(self, num_classes: int):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * (IMG_SIZE//8) * (IMG_SIZE//8), 256), nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_epoch(model, loader, criterion, optimizer=None):\n",
        "    is_train = optimizer is not None\n",
        "    model.train() if is_train else model.eval()\n",
        "\n",
        "    losses, preds, targets = [], [], []\n",
        "\n",
        "    with torch.set_grad_enabled(is_train):\n",
        "        for x, y in tqdm(loader, leave=False):\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "\n",
        "            if is_train:\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            losses.append(loss.item())\n",
        "            preds.append(logits.argmax(dim=1).detach().cpu().numpy())\n",
        "            targets.append(y.detach().cpu().numpy())\n",
        "\n",
        "    preds = np.concatenate(preds)\n",
        "    targets = np.concatenate(targets)\n",
        "    return float(np.mean(losses)), accuracy_score(targets, preds), preds, targets\n",
        "\n",
        "\n",
        "def plot_history(hist, title=\"\"):\n",
        "    plt.figure()\n",
        "    plt.plot(hist[\"train_loss\"], label=\"train_loss\")\n",
        "    plt.plot(hist[\"val_loss\"], label=\"val_loss\")\n",
        "    plt.legend()\n",
        "    plt.title(title + \" loss\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(hist[\"train_acc\"], label=\"train_acc\")\n",
        "    plt.plot(hist[\"val_acc\"], label=\"val_acc\")\n",
        "    plt.legend()\n",
        "    plt.title(title + \" accuracy\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "K = 5\n",
        "epochs = 8\n",
        "batch_size = 32\n",
        "lr = 1e-3\n",
        "\n",
        "targets = np.array([y for _, y in base_ds_for_targets.samples])\n",
        "skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=RANDOM_SEED)\n",
        "\n",
        "fold_results = []\n",
        "fold_val_preds = []\n",
        "fold_val_targets = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(targets)), targets), start=1):\n",
        "    print(f\"\\n===== Fold {fold}/{K} =====\")\n",
        "\n",
        "    train_ds = ImageFolder(DATA_DIR, transform=train_tf)\n",
        "    val_ds = ImageFolder(DATA_DIR, transform=eval_tf)\n",
        "\n",
        "    train_subset = Subset(train_ds, train_idx)\n",
        "    val_subset = Subset(val_ds, val_idx)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_subset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(\n",
        "        val_subset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    model = SmallCNN(num_classes).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    hist = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        tr_loss, tr_acc, * \\\n",
        "            _ = run_epoch(model, train_loader, criterion, optimizer)\n",
        "        va_loss, va_acc, va_pred, va_true = run_epoch(\n",
        "            model, val_loader, criterion)\n",
        "\n",
        "        hist[\"train_loss\"].append(tr_loss)\n",
        "        hist[\"train_acc\"].append(tr_acc)\n",
        "        hist[\"val_loss\"].append(va_loss)\n",
        "        hist[\"val_acc\"].append(va_acc)\n",
        "\n",
        "        print(f\"Epoch {ep:02d}: train acc={tr_acc:.3f} val acc={va_acc:.3f}\")\n",
        "\n",
        "    plot_history(hist, title=f\"Fold {fold}\")\n",
        "\n",
        "    fold_results.append({\n",
        "        \"fold\": fold,\n",
        "        \"final_train_acc\": hist[\"train_acc\"][-1],\n",
        "        \"final_val_acc\": hist[\"val_acc\"][-1],\n",
        "        \"final_val_loss\": hist[\"val_loss\"][-1],\n",
        "    })\n",
        "\n",
        "    fold_val_preds.append(va_pred)\n",
        "    fold_val_targets.append(va_true)\n",
        "\n",
        "fold_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Misclassification overview (confusion matrix)\n",
        "Aggregated over all validation predictions across folds.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_val_pred = np.concatenate(fold_val_preds)\n",
        "all_val_true = np.concatenate(fold_val_targets)\n",
        "\n",
        "cm = confusion_matrix(all_val_true, all_val_pred)\n",
        "plt.figure(figsize=(7, 7))\n",
        "plt.imshow(cm)\n",
        "plt.title(\"Confusion matrix (all folds validation)\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Optional: show example predictions on one fold\n",
        "This trains a small model for a few epochs on fold 1 and shows a few validation images with predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_examples_from_indices(ds_eval, indices, model, n=8):\n",
        "    model.eval()\n",
        "    class_names = ds_eval.classes\n",
        "    pick = random.sample(list(indices), min(n, len(indices)))\n",
        "\n",
        "    plt.figure(figsize=(12, 3))\n",
        "    for j, idx in enumerate(pick):\n",
        "        img_path, y = ds_eval.samples[idx]\n",
        "        img = Image.open(img_path)\n",
        "\n",
        "        x, _ = ds_eval[idx]\n",
        "        with torch.no_grad():\n",
        "            probs = torch.softmax(\n",
        "                model(x.unsqueeze(0).to(device)), dim=1).cpu().numpy()[0]\n",
        "        yp = int(probs.argmax())\n",
        "        conf = float(probs.max())\n",
        "\n",
        "        plt.subplot(1, len(pick), j+1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title(f\"T:{class_names[y]}\\nP:{class_names[yp]}\\n{conf:.2f}\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "train_idx, val_idx = next(iter(skf.split(np.zeros(len(targets)), targets)))\n",
        "\n",
        "train_ds_demo = ImageFolder(DATA_DIR, transform=train_tf)\n",
        "val_ds_demo = ImageFolder(DATA_DIR, transform=eval_tf)\n",
        "\n",
        "train_loader_demo = DataLoader(Subset(\n",
        "    train_ds_demo, train_idx), batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "model_demo = SmallCNN(num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_demo.parameters(), lr=lr)\n",
        "\n",
        "for ep in range(3):\n",
        "    run_epoch(model_demo, train_loader_demo, criterion, optimizer)\n",
        "\n",
        "show_examples_from_indices(val_ds_demo, val_idx, model_demo, n=8)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
