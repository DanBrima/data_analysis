{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb3f5cd",
   "metadata": {},
   "source": [
    "# Assignment — Humpback Whale Identification (Kaggle) + MLflow (OSS)\n",
    "\n",
    "This notebook is **separate** from your fish notebook (big change in dataset + evaluation).\n",
    "\n",
    "Important nuance:\n",
    "- **Train with CrossEntropyLoss** (differentiable → backprop works)\n",
    "- **Evaluate with MAP@5** (ranking metric used by the Kaggle competition; not differentiable, so it’s an eval metric, not a training loss)\n",
    "\n",
    "You’ll get:\n",
    "- Kaggle competition download via `kagglehub`\n",
    "- CSV-based dataset (not ImageFolder)\n",
    "- Train/Val/Test split + optional KFold on a filtered subset (needed because many classes have too few samples)\n",
    "- MLflow logging (params, metrics, artifacts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d70181ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip -q install kagglehub mlflow torch torchvision pandas scikit-learn pillow tqdm matplotlib ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8b97805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d700329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow tracking URI: file:/Users/danbrima/Downloads/data_analysis/mlruns\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "# ---- MLflow (OSS) tracking ----\n",
    "# Option A (simple): local filesystem runs under ./mlruns\n",
    "mlflow.set_tracking_uri(\"file:\" + str(Path.cwd() / \"mlruns\"))\n",
    "\n",
    "# Option B (remote server): uncomment if you're running an MLflow server elsewhere\n",
    "# mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "\n",
    "mlflow.set_experiment(\"assignment_humpback_whale_map5\")\n",
    "print(\"MLflow tracking URI:\", mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda285b7",
   "metadata": {},
   "source": [
    "## 1) Download the Kaggle competition dataset\n",
    "\n",
    "This uses `kagglehub.competition_download(...)`.\n",
    "\n",
    "You must have Kaggle credentials configured locally (same as usual Kaggle API usage).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a98ec38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Competition files at: /Users/danbrima/.cache/kagglehub/competitions/humpback-whale-identification\n",
      "TRAIN_CSV: /Users/danbrima/.cache/kagglehub/competitions/humpback-whale-identification/train.csv\n",
      "TRAIN_DIR: /Users/danbrima/.cache/kagglehub/competitions/humpback-whale-identification/train\n",
      "TEST_DIR : /Users/danbrima/.cache/kagglehub/competitions/humpback-whale-identification/test\n",
      "SAMPLE_SUB: /Users/danbrima/.cache/kagglehub/competitions/humpback-whale-identification/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "comp_root = Path(kagglehub.competition_download(\n",
    "    \"humpback-whale-identification\"))\n",
    "print(\"Competition files at:\", comp_root)\n",
    "\n",
    "TRAIN_CSV = comp_root / \"train.csv\"\n",
    "TRAIN_DIR = comp_root / \"train\"\n",
    "TEST_DIR = comp_root / \"test\"\n",
    "SAMPLE_SUB = comp_root / \"sample_submission.csv\"\n",
    "\n",
    "print(\"TRAIN_CSV:\", TRAIN_CSV)\n",
    "print(\"TRAIN_DIR:\", TRAIN_DIR)\n",
    "print(\"TEST_DIR :\", TEST_DIR)\n",
    "print(\"SAMPLE_SUB:\", SAMPLE_SUB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec011562",
   "metadata": {},
   "source": [
    "## 2) Load train.csv + (important) filter classes so KFold is possible\n",
    "\n",
    "This competition has **many whale IDs with very few images** (including `new_whale`).\n",
    "Stratified KFold requires each class to have enough samples, otherwise it breaks (or is meaningless).\n",
    "\n",
    "So we do:\n",
    "- Optionally drop `new_whale`\n",
    "- Keep only classes with at least `MIN_SAMPLES_PER_CLASS` samples\n",
    "- Optionally keep only the top-N most frequent IDs (to keep training lightweight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afa5151a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw rows: 25361\n",
      "Unique IDs: 5005\n",
      "           Image         Id                                               path\n",
      "0  0000e88ab.jpg  w_f48451c  /Users/danbrima/.cache/kagglehub/competitions/...\n",
      "1  0001f9222.jpg  w_c3d896a  /Users/danbrima/.cache/kagglehub/competitions/...\n",
      "2  00029d126.jpg  w_20df2c5  /Users/danbrima/.cache/kagglehub/competitions/...\n",
      "3  00050a15a.jpg  new_whale  /Users/danbrima/.cache/kagglehub/competitions/...\n",
      "4  0005c1ef8.jpg  new_whale  /Users/danbrima/.cache/kagglehub/competitions/...\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(TRAIN_CSV)\n",
    "\n",
    "# Expected columns in train.csv for this comp are Image, Id\n",
    "assert {\"Image\", \"Id\"}.issubset(\n",
    "    df.columns), f\"Unexpected train.csv columns: {df.columns.tolist()}\"\n",
    "\n",
    "df[\"path\"] = df[\"Image\"].apply(lambda x: str(TRAIN_DIR / x))\n",
    "\n",
    "print(\"Raw rows:\", len(df))\n",
    "print(\"Unique IDs:\", df[\"Id\"].nunique())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6961c620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering rows: 4057\n",
      "After filtering unique IDs: 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Id\n",
       "w_23a388d    73\n",
       "w_9b5109b    65\n",
       "w_9c506f6    62\n",
       "w_0369a5c    61\n",
       "w_700ebb4    57\n",
       "w_3de579a    54\n",
       "w_564a34b    51\n",
       "w_fd3e556    50\n",
       "w_88e4537    49\n",
       "w_2b069ba    48\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Filtering knobs (tune as needed) ----\n",
    "DROP_NEW_WHALE = True\n",
    "MIN_SAMPLES_PER_CLASS = 5   # must be >= K for KFold to be valid\n",
    "# set None to keep all filtered classes (can be huge)\n",
    "TOP_N_CLASSES = 200\n",
    "\n",
    "if DROP_NEW_WHALE:\n",
    "    df = df[df[\"Id\"] != \"new_whale\"].copy()\n",
    "\n",
    "counts = df[\"Id\"].value_counts()\n",
    "keep_ids = counts[counts >= MIN_SAMPLES_PER_CLASS].index\n",
    "df = df[df[\"Id\"].isin(keep_ids)].copy()\n",
    "\n",
    "if TOP_N_CLASSES is not None:\n",
    "    top_ids = df[\"Id\"].value_counts().head(TOP_N_CLASSES).index\n",
    "    df = df[df[\"Id\"].isin(top_ids)].copy()\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(\"After filtering rows:\", len(df))\n",
    "print(\"After filtering unique IDs:\", df[\"Id\"].nunique())\n",
    "df[\"Id\"].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0a8507",
   "metadata": {},
   "source": [
    "## 3) Dataset + transforms\n",
    "\n",
    "We are **not** using ImageFolder (labels are in CSV). We build a small Dataset wrapper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abf2d0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK labels: 200 samples: 4057\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# apply your filters here (DROP_NEW_WHALE / MIN_SAMPLES_PER_CLASS / TOP_N_CLASSES) on df\n",
    "\n",
    "df[\"img_path\"] = df[\"Image\"].apply(lambda x: str(Path(TRAIN_DIR) / x))\n",
    "\n",
    "classes = sorted(df[\"Id\"].unique())\n",
    "label2idx = {c: i for i, c in enumerate(classes)}\n",
    "df[\"y\"] = df[\"Id\"].map(label2idx).astype(int)\n",
    "\n",
    "num_classes = len(classes)\n",
    "\n",
    "assert df[\"y\"].min() == 0\n",
    "assert df[\"y\"].max() == num_classes - 1\n",
    "print(\"OK labels:\", num_classes, \"samples:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f196219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class WhaleDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        if \"img_path\" not in self.df.columns or \"y\" not in self.df.columns:\n",
    "            raise ValueError(\"df must contain columns: 'img_path' and 'y'\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(row[\"img_path\"]).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        y = torch.tensor(int(row[\"y\"]), dtype=torch.long)\n",
    "        return img, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a1fb324",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "\n",
    "    # We use light data augmentation during training to help the model generalize beyond the exact conditions seen in the dataset.\n",
    "    # RandomHorizontalFlip simulates left/right orientation changes (many subjects can appear mirrored in real photos) so the model learns orientation-invariant features.\n",
    "    # RandomRotation applies small random rotations to make the model robust to slight camera tilt and imperfect alignment.\n",
    "    # ColorJitter slightly perturbs brightness/contrast/saturation to reduce reliance on lighting and color conditions (e.g., different cameras, water/sky illumination), encouraging the network to focus on stable identity cues rather than image-specific exposure.\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=20),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "eval_tf = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6de529",
   "metadata": {},
   "source": [
    "## 4) Train/Val/Test split + loaders\n",
    "\n",
    "We make a **fixed test split** (20%), then do KFold on the remaining pool.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8f8ab44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train pool: 3245 Test: 812\n"
     ]
    }
   ],
   "source": [
    "# indices and targets for stratification\n",
    "y_all = df[\"y\"].to_numpy()\n",
    "idx_all = np.arange(len(df))\n",
    "\n",
    "# Fixed TEST split\n",
    "sss = StratifiedShuffleSplit(\n",
    "    n_splits=1, test_size=0.2, random_state=RANDOM_SEED)\n",
    "train_pool_idx, test_idx = next(sss.split(idx_all, y_all))\n",
    "\n",
    "# We use indexes because they are easier to work with for csv's\n",
    "y_train_pool = y_all[train_pool_idx]\n",
    "\n",
    "print(\"Train pool:\", len(train_pool_idx), \"Test:\", len(test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b249507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def make_loaders_from_indices(tr_idx, va_idx, te_idx, batch_size=32, num_workers=2):\n",
    "    train_ds = WhaleDataset(df.iloc[tr_idx], transform=train_tf)\n",
    "    val_ds = WhaleDataset(df.iloc[va_idx], transform=eval_tf)\n",
    "    test_ds = WhaleDataset(df.iloc[te_idx], transform=eval_tf)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=batch_size, shuffle=True,  num_workers=num_workers)\n",
    "    val_loader = DataLoader(val_ds,   batch_size=batch_size,\n",
    "                            shuffle=False, num_workers=num_workers)\n",
    "    test_loader = DataLoader(\n",
    "        test_ds,  batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8eb175",
   "metadata": {},
   "source": [
    "## 5) MAP@5 metric (competition metric)\n",
    "\n",
    "For each sample:\n",
    "- take top-5 predicted classes\n",
    "- if true class is at rank r (1..5): score = 1/r\n",
    "- else score = 0\n",
    "Then average across samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f341524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_at_k_from_probs(y_true: np.ndarray, probs: np.ndarray, k: int = 5) -> float:\n",
    "    topk = np.argsort(-probs, axis=1)[:, :k]  # (N, k)\n",
    "    scores = []\n",
    "    for i in range(len(y_true)):\n",
    "        true = y_true[i]\n",
    "        row = topk[i]\n",
    "        hit = np.where(row == true)[0]\n",
    "        scores.append(0.0 if len(hit) == 0 else 1.0 / (int(hit[0]) + 1))\n",
    "\n",
    "    return float(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f6f7a9",
   "metadata": {},
   "source": [
    "## 6) Model: pretrained ResNet18 (simple baseline)\n",
    "\n",
    "(You can swap later to EfficientNet / DenseNet / etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5dedea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallCNN(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.img_size = IMG_SIZE\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "        )\n",
    "\n",
    "        # after 3 pools: H,W are divided by 8\n",
    "        feat_hw = self.img_size // 8\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * feat_hw * feat_hw, 256), nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea14e881",
   "metadata": {},
   "source": [
    "## 7) Training/eval utilities (loss = CrossEntropy, metrics include MAP@5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95470dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(model, loader, criterion, optimizer=None):\n",
    "    is_train = optimizer is not None\n",
    "    model.train() if is_train else model.eval()\n",
    "\n",
    "    losses = []\n",
    "    all_probs = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.set_grad_enabled(is_train):\n",
    "        for x, y in tqdm(loader, leave=False):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            # right before: loss = criterion(logits, y)\n",
    "            assert y.dtype == torch.long and y.ndim == 1, (y.dtype, y.shape)\n",
    "            assert int(y.min()) >= 0 and int(\n",
    "                y.max()) < logits.shape[1], (int(y.min()), int(y.max()), logits.shape)\n",
    "            loss = criterion(logits, y)\n",
    "            if is_train:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            probs = torch.softmax(logits, dim=1).detach().cpu().numpy()\n",
    "            all_probs.append(probs)\n",
    "            all_targets.append(y.detach().cpu().numpy())\n",
    "\n",
    "    probs = np.vstack(all_probs)\n",
    "    targets = np.concatenate(all_targets)\n",
    "\n",
    "    pred = probs.argmax(axis=1)\n",
    "    acc = float(accuracy_score(targets, pred))\n",
    "    map5 = map_at_k_from_probs(targets, probs, k=5)\n",
    "\n",
    "    return float(np.mean(losses)), acc, map5, probs, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02106355",
   "metadata": {},
   "source": [
    "## 8) KFold training on train_pool + MLflow logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03acd5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'WhaleDataset' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "# ---- Settings ----\n",
    "K = 2          # set 2 for faster debugging\n",
    "EPOCHS = 1     # set 1 for faster debugging\n",
    "BATCH_SIZE = 32\n",
    "LR = 1e-4\n",
    "# maybe use WEIGHT_DECAY later\n",
    "\n",
    "skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "fold_rows = []\n",
    "fold_test_probs = []\n",
    "test_targets_global = None\n",
    "\n",
    "for fold, (tr_rel, va_rel) in enumerate(skf.split(np.zeros(len(train_pool_idx)), y_train_pool), start=1):\n",
    "    tr_idx = train_pool_idx[tr_rel]\n",
    "    va_idx = train_pool_idx[va_rel]\n",
    "\n",
    "    train_loader, val_loader, test_loader = make_loaders_from_indices(\n",
    "        tr_idx, va_idx, test_idx,\n",
    "        batch_size=BATCH_SIZE, num_workers=2\n",
    "    )\n",
    "\n",
    "    model = SmallCNN(num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), lr=LR)\n",
    "\n",
    "    run_name = f\"fold_{fold}_smallcnn_3_32_64\"\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        mlflow.log_params({\n",
    "            \"dataset\": \"humpback-whale-identification\",\n",
    "            \"model\": \"smallcnn_3_32_64\",\n",
    "            \"num_classes\": num_classes,\n",
    "            \"K\": K,\n",
    "            \"epochs\": EPOCHS,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"lr\": LR,\n",
    "            \"drop_new_whale\": DROP_NEW_WHALE,\n",
    "            \"min_samples_per_class\": MIN_SAMPLES_PER_CLASS,\n",
    "            \"top_n_classes\": TOP_N_CLASSES,\n",
    "            \"img_size\": IMG_SIZE,\n",
    "        })\n",
    "\n",
    "        for ep in range(1, EPOCHS + 1):\n",
    "            tr_loss, tr_acc, tr_map5, _, _ = run_epoch(\n",
    "                model, train_loader, criterion, optimizer)\n",
    "            va_loss, va_acc, va_map5, _, _ = run_epoch(\n",
    "                model, val_loader, criterion)\n",
    "\n",
    "            print(f\"Fold {fold} | Epoch {ep:02d} | \"\n",
    "                  f\"train: loss={tr_loss:.4f} acc={tr_acc:.4f} map5={tr_map5:.4f} | \"\n",
    "                  f\"val:   loss={va_loss:.4f} acc={va_acc:.4f} map5={va_map5:.4f}\")\n",
    "\n",
    "            mlflow.log_metrics({\n",
    "                \"train_loss\": tr_loss,\n",
    "                \"train_acc\": tr_acc,\n",
    "                \"train_map5\": tr_map5,\n",
    "                \"val_loss\": va_loss,\n",
    "                \"val_acc\": va_acc,\n",
    "                \"val_map5\": va_map5,\n",
    "            }, step=ep)\n",
    "\n",
    "        te_loss, te_acc, te_map5, te_probs, te_targets = run_epoch(\n",
    "            model, test_loader, criterion)\n",
    "        print(\n",
    "            f\"Fold {fold} TEST: loss={te_loss:.4f} acc={te_acc:.4f} map5={te_map5:.4f}\")\n",
    "\n",
    "        mlflow.log_metrics({\n",
    "            \"test_loss\": te_loss,\n",
    "            \"test_acc\": te_acc,\n",
    "            \"test_map5\": te_map5,\n",
    "        })\n",
    "\n",
    "        mlflow.pytorch.log_model(model, artifact_path=\"model\")\n",
    "\n",
    "        fold_test_probs.append(te_probs)\n",
    "        test_targets_global = te_targets\n",
    "\n",
    "        fold_rows.append({\n",
    "            \"fold\": fold,\n",
    "            \"val_acc_last\": va_acc,\n",
    "            \"val_map5_last\": va_map5,\n",
    "            \"test_acc\": te_acc,\n",
    "            \"test_map5\": te_map5,\n",
    "        })\n",
    "\n",
    "df_folds = pd.DataFrame(fold_rows)\n",
    "df_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a898c159",
   "metadata": {},
   "source": [
    "## 9) Mean-of-folds ensemble on TEST (average probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f25199",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_test_probs_arr = np.stack(fold_test_probs, axis=0)  # (K, Ntest, C)\n",
    "mean_probs = fold_test_probs_arr.mean(axis=0)              # (Ntest, C)\n",
    "\n",
    "mean_pred = mean_probs.argmax(axis=1)\n",
    "ensemble_acc = float(accuracy_score(test_targets_global, mean_pred))\n",
    "ensemble_map5 = map_at_k_from_probs(test_targets_global, mean_probs, k=5)\n",
    "\n",
    "print(\"Ensemble TEST acc :\", ensemble_acc)\n",
    "print(\"Ensemble TEST map5:\", ensemble_map5)\n",
    "\n",
    "with mlflow.start_run(run_name=\"ensemble_mean_of_folds\"):\n",
    "    mlflow.log_params({\n",
    "        \"dataset\": \"humpback-whale-identification\",\n",
    "        \"model\": \"resnet18\",\n",
    "        \"ensemble\": \"mean_probs\",\n",
    "        \"K\": K,\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"lr\": LR,\n",
    "        \"num_classes\": num_classes,\n",
    "    })\n",
    "    mlflow.log_metrics({\n",
    "        \"ensemble_test_acc\": ensemble_acc,\n",
    "        \"ensemble_test_map5\": ensemble_map5,\n",
    "    })\n",
    "\n",
    "df_compare = df_folds.copy()\n",
    "df_compare[\"ensemble_test_acc\"] = ensemble_acc\n",
    "df_compare[\"ensemble_test_map5\"] = ensemble_map5\n",
    "df_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2f68fb",
   "metadata": {},
   "source": [
    "## 10) Viewing MLflow results\n",
    "\n",
    "If you used `file:.../mlruns`, open a terminal in this notebook folder and run:\n",
    "\n",
    "```bash\n",
    "mlflow ui\n",
    "```\n",
    "\n",
    "Then open the printed local URL in your browser.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
